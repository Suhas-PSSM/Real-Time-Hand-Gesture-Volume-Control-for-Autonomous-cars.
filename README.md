# ğŸš— Real-Time Hand Gesture Volume Control for Autonomous Cars

An **AI-powered hand gesture recognition system** that lets users **control car audio volume** using simple, touch-free gestures.  
Designed for **autonomous and next-gen vehicles**, this project enhances the in-car experience through intuitive, safe, and contactless interaction.

---

## ğŸ¯ Features
- ğŸµ **Touch-free volume control** using hand gestures   
- âš¡ **Real-time hand tracking** (â‰¤120 ms latency) with MediaPipe  
- ğŸ§  **AI-based gesture recognition** for robust performance in various lighting conditions  
- ğŸ”’ **On-device processing** for low latency and privacy  

---

## ğŸ§© Tech Stack
- **Languages:** Python, OpenCV  
- **AI Frameworks:** MediaPipe, TensorFlow Lite / PyTorch  
- **OS APIs:** pycaw (Windows), amixer (Linux)

---

## ğŸ¥ Demo

![Gesture Volume Demo](assets/demo.gif)

---

## ğŸ“Š Future Improvements
- Add support for **multi-hand and multi-gesture controls** (e.g., track change, mute).   
- Improve gesture detection under **low-light or occluded conditions**.  

---

## ğŸ¤ Contributing
Contributions are welcome!  
If you'd like to improve this project:
1. Fork the repository  
2. Create a new branch (`feature/your-feature`)  
3. Commit your changes  
4. Open a Pull Request ğŸ‰  

---

â­ **If you like this project, give it a star!**
